{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import scipy\n",
    " \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder,LabelBinarizer,OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,f1_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "import commonfunction\n",
    "\n",
    "\n",
    "class trainmodel:\n",
    "                    \n",
    "    def __init__(self):        \n",
    "        self.train_df = self.test_df = self.Y = pd.DataFrame()\n",
    "        self.train_df = pd.read_csv(\"../../data/processed/train.csv\")\n",
    "        self.test_df = pd.read_csv(\"../../data/processed/test.csv\")                    \n",
    "        \n",
    "    def transform_target(self):\n",
    "        \n",
    "        le  = LabelBinarizer()\n",
    "        cat_arr = le.fit_transform(self.train_df['cat'])\n",
    "        cat_df = pd.DataFrame(data=cat_arr,columns=le.classes_)        \n",
    "        self.train_df['subcat'] = np.where(pd.isnull(self.train_df['subcat']),'NaN',self.train_df['subcat'])\n",
    "        subcat_arr = le.fit_transform(self.train_df['subcat'])\n",
    "        subcat_df = pd.DataFrame(data=subcat_arr,columns=le.classes_)    \n",
    "        self.Y = pd.concat([cat_df,subcat_df],axis=1)        \n",
    "        self.Y.drop('NaN',inplace=True,axis=1)\n",
    "        #print('Y value', self.Y.columns)\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \n",
    "        col_todrop = ['cat','subcat','Unnamed: 0','document_id']\n",
    "        for col in col_todrop:\n",
    "            self.train_df.drop(col,axis=1,inplace=True)          \n",
    "            \n",
    "    def prepare_validationset(self):\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(self.train_df['content'], self.Y, \n",
    "                                                            test_size=0.33, random_state=42)                 \n",
    "        return(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "    def createmodel(self):\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test =  self.prepare_validationset()\n",
    "        #X_train, X_test, Y_train, Y_test = train_test_split(self.train_df['content'], self.Y,test_size=0.33, random_state=42)                             \n",
    "        X_train_transposed =X_train.T\n",
    "        self.pipe = Pipeline([\n",
    "                    ('cv', CountVectorizer(ngram_range=(1, 3))),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('LP_GNB', LabelPowerset(GaussianNB()))])\n",
    "        # train\n",
    "        self.pipe.fit(X_train_transposed, Y_train)\n",
    "        \n",
    "        # predict\n",
    "        prediction = self.pipe.predict(X_test)\n",
    "         \n",
    "        print('validation dataset accuracy is {}'.format(accuracy_score(Y_test, prediction)))           \n",
    "        print('Hamming loss is {}'.format(hamming_loss(Y_test, prediction)))\n",
    "        print('F1 Score is {}'.format(f1_score(Y_test, prediction,average='samples')))\n",
    "        \n",
    "        return()\n",
    "    \n",
    "    def termfreq(self,n_comp):\n",
    "        \n",
    "        tfidfvec = TfidfVectorizer(ngram_range=(1,3), strip_accents='unicode',\n",
    "                       lowercase =True, analyzer='word', token_pattern=r'\\w+',\n",
    "                       stop_words = 'english')\n",
    "        \n",
    "        tfidf = tfidfvec.fit_transform(self.train_df['content'])  \n",
    "        self.train_df.drop('content',inplace=True,axis=1)\n",
    "        self.train_df = pd.DataFrame(tfidf.toarray(), columns=tfidfvec.get_feature_names())\n",
    "        \n",
    "        '''\n",
    "        df1 = pd.DataFrame(tfidf.toarray(), columns=tfidfvec.get_feature_names())\n",
    "        self.train_df = pd.concat([self.train_df, df1], axis=1)\n",
    "        svdT = TruncatedSVD(n_components=n_comp)\n",
    "        self.train_df = svdT.fit_transform(self.train_df) \n",
    "        \n",
    "        \n",
    "        test_tfidf = tfidfvec.transform(self.test_df['content'])\n",
    "        self.test_df.drop('content',inplace=True,axis=1)\n",
    "        df1 = pd.DataFrame(test_tfidf.toarray(), columns=tfidfvec.get_feature_names())\n",
    "        self.test_df = pd.concat([self.test_df, df1], axis=1)\n",
    "        self.test_df = svdT.transform(self.test_tfidf)                 \n",
    "        '''\n",
    "        \n",
    "    def createmodel_2(self):\n",
    "                        \n",
    "        self.termfreq()                      \n",
    "        clf = LabelPowerset(GaussianNB())\n",
    "        X_train, X_test, Y_train, Y_test =  self.prepare_validationset()\n",
    "        clf.fit(X_train,Y_train)\n",
    "        prediction = clf.predict(X_test)\n",
    "        \n",
    "        # predict\n",
    "        # prediction = self.pipe.predict(X_test)\n",
    "         \n",
    "        print('validation dataset accuracy is {}'.format(accuracy_score(Y_test, prediction)))           \n",
    "        print('Hamming loss is {}'.format(hamming_loss(Y_test, prediction)))\n",
    "        print('F1 Score is {}'.format(f1_score(Y_test, prediction,average='samples')))\n",
    "        \n",
    "        return()\n",
    "    \n",
    "    def prepare_testdata(self,fname):\n",
    "        \n",
    "        self.test_df = pd.read_csv(fname)         \n",
    "        self.test_id = self.test_df['document_id']\n",
    "        \n",
    "        col_todrop = ['document_id','Unnamed: 0']\n",
    "        for col in col_todrop:\n",
    "            self.test_df.drop(col,axis=1,inplace=True)            \n",
    "        \n",
    "    \n",
    "    def predict_testdataset(self):\n",
    "         \n",
    "        test_predicitions = self.pipe.predict(self.test_df['content'])         \n",
    "        return(test_predicitions)\n",
    "    \n",
    "    \n",
    "    def get_testdata(self):\n",
    "        return(self.test_df)\n",
    "    \n",
    "    def get_traindata(self):\n",
    "        return(self.train_df)\n",
    "    \n",
    "    def get_target(self):\n",
    "        return(self.Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X): \n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper:\n",
    "    \n",
    "    def __init__(self,pipe,models, params):\n",
    "        \n",
    "        '''\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        '''\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.pipe = pipe\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "    \n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            \n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]   \n",
    "            self.pipe.named_steps['classifier'].set_params(classifier=model)             \n",
    "            gs = GridSearchCV(self.pipe, params, cv=cv, n_jobs=n_jobs, \n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "    \n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        \n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            new = {}            \n",
    "            new.update(params) \n",
    "            new.update(d)\n",
    "            return pd.Series(new)\n",
    "            #return pd.Series(dict(list(**params.items()) + list(**d.items()) ) )\n",
    "            \n",
    "                      \n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "        \n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        \n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        \n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = trainmodel()\n",
    "model.transform_target()\n",
    "model.prepare_data()\n",
    "\n",
    "train_df  = model.get_traindata()\n",
    "target = model.get_target()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_df,target, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayap/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jayap/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:  4.2min finished\n",
      "/home/jayap/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:61: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>classifier__classifier__max_depth</th>\n",
       "      <th>classifier__classifier__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.588073</td>\n",
       "      <td>0.595691</td>\n",
       "      <td>0.604637</td>\n",
       "      <td>0.00682695</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.574378</td>\n",
       "      <td>0.590844</td>\n",
       "      <td>0.613742</td>\n",
       "      <td>0.016701</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.191262</td>\n",
       "      <td>0.295278</td>\n",
       "      <td>0.415199</td>\n",
       "      <td>0.0921109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.186697</td>\n",
       "      <td>0.293286</td>\n",
       "      <td>0.413788</td>\n",
       "      <td>0.0932303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                estimator min_score mean_score max_score   std_score  \\\n",
       "3  RandomForestClassifier  0.588073   0.595691  0.604637  0.00682695   \n",
       "2  RandomForestClassifier  0.574378   0.590844  0.613742    0.016701   \n",
       "0      AdaBoostClassifier  0.191262   0.295278  0.415199   0.0921109   \n",
       "1      AdaBoostClassifier  0.186697   0.293286  0.413788   0.0932303   \n",
       "\n",
       "  classifier__classifier__max_depth classifier__classifier__n_estimators  \n",
       "3                                32                                  NaN  \n",
       "2                                16                                  NaN  \n",
       "0                               NaN                                   16  \n",
       "1                               NaN                                   32  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipeline  = Pipeline([\n",
    "    ('select_column', ColumnSelector(key='content')),\n",
    "    ('cvec',CountVectorizer(ngram_range=(1,3))),\n",
    "    ('svd', TruncatedSVD(n_components=1000)),\n",
    "    ('classifier', LabelPowerset())      \n",
    "])\n",
    "models1 = {     \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    #'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    #'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = {          \n",
    "    'RandomForestClassifier': {'classifier__classifier__max_depth': [16, 32]},\n",
    "    'AdaBoostClassifier' :  {'classifier__classifier__n_estimators': [16, 32]}\n",
    "}\n",
    "\n",
    "'''\n",
    "models1 = {     \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    #'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = {     \n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },    \n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "helper1 = EstimatorSelectionHelper(pipeline, models1, params1)\n",
    "helper1.fit(X_train, Y_train, scoring='f1_weighted', n_jobs=2)\n",
    "\n",
    "helper1.score_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "EstimatorSelectionHelper instance has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-48e294ed4e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hamming loss is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhamming_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation dataset accuracy is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: EstimatorSelectionHelper instance has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# test the classifier\n",
    "prediction = helper1.predict(X_test)\n",
    "\n",
    "print('Hamming loss is {}'.format(hamming_loss(Y_test, prediction)))\n",
    "print('validation dataset accuracy is {}'.format(accuracy_score(Y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('select_column', ColumnSelector(key='content')),\n",
    "    ('cvec',CountVectorizer(ngram_range=(1,3))),\n",
    "    ( 'svd', TruncatedSVD() ),\n",
    "    ('classifier',LabelPowerset()),        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier='RandomForestClassifier()',\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(classifier='RandomForestClassifier()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier='LogisticRegression()', require_dense=[True, True])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.named_steps['classifier'].set_params(classifier='LogisticRegression()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline2.steps.append(['classifier',clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('select_column', ColumnSelector(key='content')), ('cvec', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, ...ue])), ['classifier', LabelPowerset(classifier='LogisticRegression()', require_dense=[True, True])]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "clf = LabelPowerset()\n",
    "clf.set_params(classifier='RandomForestClassifier()')\n",
    "clf.set_params(classifier='LogisticRegression()')\n",
    "print(clf.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = trainmodel()\n",
    "model.transform_target()\n",
    " \n",
    "model.prepare_data()\n",
    "\n",
    "\n",
    "#Read the data for which the label to be predicted......\n",
    "model.prepare_testdata(\"../../data/processed/test.csv\")\n",
    "\n",
    "#test_result is the predicted label \n",
    "test_result = model.predict_testdataset()\n",
    "\n",
    "#Convert the binary n-array to the corresponding label\n",
    "#resultant array will have two columns - cat, subcat\n",
    "\n",
    "data = np.zeros(shape=[test_result.shape[0],2])\n",
    "data_str = data.astype(str)\n",
    "\n",
    "cx = scipy.sparse.coo_matrix(test_result)\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):      \n",
    "    if(data_str[i][0] == '0.0'):\n",
    "        #print(\"Inside if stmt ...... \",i,j)\n",
    "        data_str[i][0] = commonfunction.getlabelname(j)\n",
    "    else:\n",
    "        #print(\"Inside if else ...... \",i,j)\n",
    "        data_str[i][1] = commonfunction.getlabelname(j)         \n",
    "\n",
    "test_df = pd.read_csv(\"../../data/processed/test.csv\")\n",
    "test_id = test_df['document_id']\n",
    "label_df = pd.DataFrame({' ':test_id,'cat':data_str[:,0],'subcat':data_str[:,1]})\n",
    "label_df.to_csv(\"../../data/processed/predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss is 0.0611672278339\n",
      "validation dataset accuracy is 0.265512265512\n"
     ]
    }
   ],
   "source": [
    "# train the classifier\n",
    "model = pipe.fit(X_train.T, Y_train)\n",
    "\n",
    "# test the classifier\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print('Hamming loss is {}'.format(hamming_loss(Y_test, prediction)))\n",
    "print('validation dataset accuracy is {}'.format(accuracy_score(Y_test, prediction)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
