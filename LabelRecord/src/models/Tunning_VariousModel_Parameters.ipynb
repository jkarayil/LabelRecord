{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import scipy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder,LabelBinarizer,OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,f1_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import commonfunction\n",
    "\n",
    "\n",
    "model = trainmodel()\n",
    "model.transform_target()\n",
    "model.prepare_data()\n",
    "\n",
    "train_df  = model.get_traindata()\n",
    "target = model.get_target()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_df,target, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayap/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jayap/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:  4.2min finished\n",
      "/home/jayap/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:61: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>classifier__classifier__max_depth</th>\n",
       "      <th>classifier__classifier__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.588073</td>\n",
       "      <td>0.595691</td>\n",
       "      <td>0.604637</td>\n",
       "      <td>0.00682695</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.574378</td>\n",
       "      <td>0.590844</td>\n",
       "      <td>0.613742</td>\n",
       "      <td>0.016701</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.191262</td>\n",
       "      <td>0.295278</td>\n",
       "      <td>0.415199</td>\n",
       "      <td>0.0921109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.186697</td>\n",
       "      <td>0.293286</td>\n",
       "      <td>0.413788</td>\n",
       "      <td>0.0932303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                estimator min_score mean_score max_score   std_score  \\\n",
       "3  RandomForestClassifier  0.588073   0.595691  0.604637  0.00682695   \n",
       "2  RandomForestClassifier  0.574378   0.590844  0.613742    0.016701   \n",
       "0      AdaBoostClassifier  0.191262   0.295278  0.415199   0.0921109   \n",
       "1      AdaBoostClassifier  0.186697   0.293286  0.413788   0.0932303   \n",
       "\n",
       "  classifier__classifier__max_depth classifier__classifier__n_estimators  \n",
       "3                                32                                  NaN  \n",
       "2                                16                                  NaN  \n",
       "0                               NaN                                   16  \n",
       "1                               NaN                                   32  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline  = Pipeline([\n",
    "    ('select_column', ColumnSelector(key='content')),\n",
    "    ('cvec',CountVectorizer(ngram_range=(1,3))),\n",
    "    ('svd', TruncatedSVD(n_components=1000)),\n",
    "    ('classifier', LabelPowerset())      \n",
    "])\n",
    "models1 = {     \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'XGBClassifier' : XGBClassifier(),\n",
    "    'LogisticRegression' : LogisticRegression()\n",
    "    'MultinomialNB' : MultinomialNB()\n",
    "    #'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = {          \n",
    "    'RandomForestClassifier': {'classifier__classifier__max_depth': [16, 32]},\n",
    "    'AdaBoostClassifier' :  {'classifier__classifier__n_estimators': [16, 32]}\n",
    "    'GradientBoostingClassifier': { 'classifier__classifier__n_estimators': [16, 32], \n",
    "                                   'classifier__classifier__learning_rate': [0.8, 1.0] \n",
    "                                  }\n",
    "    'XGBClassifier' : { 'classifier__classifier__max_depth' : [6],\n",
    "                      'classifier__classifier__learning_rate': [0.05,0.001],\n",
    "                      'classifier__classifier__max_depth': [6],\n",
    "                      'classifier__classifier__min_child_weight': [11],              \n",
    "                      'classifier__classifier__subsample': [0.8],\n",
    "                      'classifier__classifier__colsample_bytree': [0.7],\n",
    "                      'classifier__classifier__n_estimators': [100]                                \n",
    "    }\n",
    "    \n",
    "    'LogisticRegression' : {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10]\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    " \n",
    "\n",
    "helper1 = EstimatorSelectionHelper(pipeline, models1, params1)\n",
    "helper1.fit(X_train, Y_train, scoring='f1_weighted', n_jobs=2)\n",
    "\n",
    "helper1.score_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "EstimatorSelectionHelper instance has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-48e294ed4e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hamming loss is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhamming_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation dataset accuracy is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: EstimatorSelectionHelper instance has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# test the classifier\n",
    "prediction = helper1.predict(X_test)\n",
    "\n",
    "print('Hamming loss is {}'.format(hamming_loss(Y_test, prediction)))\n",
    "print('validation dataset accuracy is {}'.format(accuracy_score(Y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('select_column', ColumnSelector(key='content')),\n",
    "    ('cvec',CountVectorizer(ngram_range=(1,3))),\n",
    "    ( 'svd', TruncatedSVD() ),\n",
    "    ('classifier',LabelPowerset()),        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = trainmodel()\n",
    "model.transform_target()\n",
    " \n",
    "model.prepare_data()\n",
    "\n",
    "\n",
    "#Read the data for which the label to be predicted......\n",
    "model.prepare_testdata(\"../../data/processed/test.csv\")\n",
    "\n",
    "#test_result is the predicted label \n",
    "test_result = model.predict_testdataset()\n",
    "\n",
    "#Convert the binary n-array to the corresponding label\n",
    "#resultant array will have two columns - cat, subcat\n",
    "\n",
    "data = np.zeros(shape=[test_result.shape[0],2])\n",
    "data_str = data.astype(str)\n",
    "\n",
    "cx = scipy.sparse.coo_matrix(test_result)\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):      \n",
    "    if(data_str[i][0] == '0.0'):\n",
    "        #print(\"Inside if stmt ...... \",i,j)\n",
    "        data_str[i][0] = commonfunction.getlabelname(j)\n",
    "    else:\n",
    "        #print(\"Inside if else ...... \",i,j)\n",
    "        data_str[i][1] = commonfunction.getlabelname(j)         \n",
    "\n",
    "test_df = pd.read_csv(\"../../data/processed/test.csv\")\n",
    "test_id = test_df['document_id']\n",
    "label_df = pd.DataFrame({' ':test_id,'cat':data_str[:,0],'subcat':data_str[:,1]})\n",
    "label_df.to_csv(\"../../data/processed/predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss is 0.0611672278339\n",
      "validation dataset accuracy is 0.265512265512\n"
     ]
    }
   ],
   "source": [
    "# train the classifier\n",
    "model = pipe.fit(X_train.T, Y_train)\n",
    "\n",
    "# test the classifier\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print('Hamming loss is {}'.format(hamming_loss(Y_test, prediction)))\n",
    "print('validation dataset accuracy is {}'.format(accuracy_score(Y_test, prediction)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
