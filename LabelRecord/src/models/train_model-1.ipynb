{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayap/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import scipy\n",
    " \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder,LabelBinarizer,OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split \n",
    "\n",
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,f1_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "import commonfunction\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"test.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class trainmodel:\n",
    "                    \n",
    "    def __init__(self):        \n",
    "        self.train_df = self.test_df = self.Y = pd.DataFrame()\n",
    "        self.train_df = pd.read_csv(\"../../data/processed/train.csv\")\n",
    "        self.test_df = pd.read_csv(\"../../data/processed/test.csv\")\n",
    "        logging.debug(\"The column in train set \", self.train_df.columns, \"--------------\")\n",
    "        \n",
    "    def transform_target(self):\n",
    "        \n",
    "        le  = LabelBinarizer()\n",
    "        cat_arr = le.fit_transform(self.train_df['cat'])\n",
    "        cat_df = pd.DataFrame(data=cat_arr,columns=le.classes_)\n",
    "        logging.debug('cat classes',le.classes_)\n",
    "        self.train_df['subcat'] = np.where(pd.isnull(self.train_df['subcat']),'NaN',self.train_df['subcat'])\n",
    "        subcat_arr = le.fit_transform(self.train_df['subcat'])\n",
    "        subcat_df = pd.DataFrame(data=subcat_arr,columns=le.classes_)\n",
    "        logging.debug('subcat classes',le.classes_)\n",
    "        self.Y = pd.concat([cat_df,subcat_df],axis=1)        \n",
    "        self.Y.drop('NaN',inplace=True,axis=1)\n",
    "        #print('Y value', self.Y.columns)\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \n",
    "        col_todrop = ['cat','subcat','Unnamed: 0','document_id']\n",
    "        for col in col_todrop:\n",
    "            self.train_df.drop(col,axis=1,inplace=True)          \n",
    "            \n",
    "    def prepare_validationset(self):\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(self.train_df['content'], self.Y, \n",
    "                                                            test_size=0.33, random_state=42)                 \n",
    "        return(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "    def createmodel(self):\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test =  self.prepare_validationset()\n",
    "        #X_train, X_test, Y_train, Y_test = train_test_split(self.train_df['content'], self.Y,test_size=0.33, random_state=42)                             \n",
    "        X_train_transposed =X_train.T\n",
    "        self.pipe = Pipeline([\n",
    "                    ('cv', CountVectorizer(ngram_range=(1, 3))),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('LP_GNB', LabelPowerset(GaussianNB()))])\n",
    "        # train\n",
    "        self.pipe.fit(X_train_transposed, Y_train)\n",
    "        \n",
    "        # predict\n",
    "        prediction = self.pipe.predict(X_test)\n",
    "         \n",
    "        print('validation dataset accuracy is {}'.format(accuracy_score(Y_test, prediction)))           \n",
    "        print('Hamming loss is {}'.format(hamming_loss(Y_test, prediction)))\n",
    "        print('F1 Score is {}'.format(f1_score(Y_test, prediction,average='samples')))\n",
    "        \n",
    "        return()\n",
    "    \n",
    "    def termfreq(self):\n",
    "        \n",
    "        tfidfvec = TfidfVectorizer(ngram_range=(1,3), strip_accents='unicode',\n",
    "                       lowercase =True, analyzer='word', token_pattern=r'\\w+',\n",
    "                       stop_words = 'english')\n",
    "        \n",
    "        tfidf = tfidfvec.fit_transform(self.train_df['content'])  \n",
    "        self.train_df.drop('content',inplace=True,axis=1)\n",
    "        df1 = pd.DataFrame(tfidf.toarray(), columns=tfidfvec.get_feature_names())\n",
    "        self.train_df = pd.concat([self.train_df, df1], axis=1)\n",
    "        svdT = TruncatedSVD(n_components=4000)\n",
    "        self.train_df = svdT.fit_transform(self.train_df)        \n",
    "        \n",
    "        test_tfidf = tfidfvec.transform(self.test_df['content'])\n",
    "        self.test_df.drop('content',inplace=True,axis=1)\n",
    "        df1 = pd.DataFrame(test_tfidf.toarray(), columns=tfidfvec.get_feature_names())\n",
    "        self.test_df = pd.concat([self.test_df, df1], axis=1)\n",
    "        self.test_df = svdT.transform(self.test_tfidf)\n",
    "        \n",
    "         \n",
    "    \n",
    "    def createmodel_2(self):\n",
    "                        \n",
    "        self.termfreq()              \n",
    "        \n",
    "        clf = LabelPowerset(GaussianNB())\n",
    "        X_train, X_test, Y_train, Y_test =  self.prepare_validationset()\n",
    "        clf.fit(X_train,Y_train)\n",
    "        prediction = clf.predict(X_test)\n",
    "        \n",
    "        # predict\n",
    "        # prediction = self.pipe.predict(X_test)\n",
    "         \n",
    "        print('validation dataset accuracy is {}'.format(accuracy_score(Y_test, prediction)))           \n",
    "        print('Hamming loss is {}'.format(hamming_loss(Y_test, prediction)))\n",
    "        print('F1 Score is {}'.format(f1_score(Y_test, prediction,average='samples')))\n",
    "        \n",
    "        return()\n",
    "    \n",
    "    def prepare_testdata(self,fname):\n",
    "        \n",
    "        self.test_df = pd.read_csv(fname)\n",
    "        logging.debug(\"--- Before ----\",self.test_df.shape)\n",
    "        self.test_id = self.test_df['document_id']\n",
    "        \n",
    "        col_todrop = ['document_id','Unnamed: 0']\n",
    "        for col in col_todrop:\n",
    "            self.test_df.drop(col,axis=1,inplace=True)\n",
    "            \n",
    "        logging.debug(\"--- After ----\",self.test_df.shape)\n",
    "        \n",
    "    \n",
    "    def predict_testdataset(self):\n",
    "         \n",
    "        test_predicitions = self.pipe.predict(self.test_df['content'])\n",
    "        logging.debug('test predictions shape', test_predicitions.shape)\n",
    "        return(test_predicitions)\n",
    "    \n",
    "    \n",
    "    def get_testdata(self):\n",
    "        return(self.test_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../data/processed/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 861, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 734, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 465, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 329, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Logged from file <ipython-input-2-a2a327bf8da9>, line 7\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 861, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 734, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 465, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 329, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Logged from file <ipython-input-2-a2a327bf8da9>, line 14\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 861, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 734, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 465, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 329, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Logged from file <ipython-input-2-a2a327bf8da9>, line 18\n"
     ]
    }
   ],
   "source": [
    "model = trainmodel()\n",
    "model.transform_target()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline code\n",
    "validation dataset accuracy is 0.802211302211\n",
    "Hamming loss is 0.0293475293475\n",
    "F1 Score is 0.853808353808\n",
    "\n",
    "### after adding the last page of the record\n",
    "validation dataset accuracy is 0.815295815296\n",
    "Hamming loss is 0.0282186948854\n",
    "F1 Score is 0.857864357864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset accuracy is 0.815295815296\n",
      "Hamming loss is 0.0282186948854\n",
      "F1 Score is 0.857864357864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prepare_data()\n",
    "model.createmodel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 861, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 734, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 465, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 329, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Logged from file <ipython-input-134-a2a327bf8da9>, line 98\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 861, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 734, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 465, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 329, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Logged from file <ipython-input-134-a2a327bf8da9>, line 105\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 861, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 734, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 465, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/jayap/anaconda2/lib/python2.7/logging/__init__.py\", line 329, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Logged from file <ipython-input-134-a2a327bf8da9>, line 111\n"
     ]
    }
   ],
   "source": [
    "#Read the data for which the label to be predicted......\n",
    "model.prepare_testdata(\"../../data/processed/test.csv\")\n",
    "\n",
    "#test_result is the predicted label \n",
    "test_result = model.predict_testdataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert the binary n-array to the corresponding label\n",
    "#resultant array will have two columns - cat, subcat\n",
    "\n",
    "data = np.zeros(shape=[test_result.shape[0],2])\n",
    "data_str = data.astype(str)\n",
    "\n",
    "cx = scipy.sparse.coo_matrix(test_result)\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):      \n",
    "    if(data_str[i][0] == '0.0'):\n",
    "        #print(\"Inside if stmt ...... \",i,j)\n",
    "        data_str[i][0] = commonfunction.getlabelname(j)\n",
    "    else:\n",
    "        #print(\"Inside if else ...... \",i,j)\n",
    "        data_str[i][1] = commonfunction.getlabelname(j)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../data/processed/test.csv\")\n",
    "test_id = test_df['document_id']\n",
    "label_df = pd.DataFrame({' ':test_id,'cat':data_str[:,0],'subcat':data_str[:,1]})\n",
    "label_df.to_csv(\"../../data/processed/predicted.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
