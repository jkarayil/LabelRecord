{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class preprocessData(TransformerMixin):         \n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def getdataframe(self):\n",
    "        return(self.df)\n",
    "    \n",
    "    def remove_noun(self,sentence):\n",
    "        \n",
    "        tagged_sentence = nltk.tag.pos_tag(sentence)\n",
    "        edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
    "        return (' '.join(edited_sentence))\n",
    "\n",
    "    # Remove punctuations from the text\n",
    "    def remove_stop_punc(self,text)\n",
    "    \n",
    "        remove = string.punctuation\n",
    "        remove = remove.replace(\"?\", \"\")\n",
    "        cleaned_text = text.translate(None, remove)\n",
    "        # Converting all upper cases to lower cases\n",
    "        cleaned_text = [word.lower() for word in cleaned_text.split()]\n",
    "        # Removing stopwords (takes a relatively longer amount of time)\n",
    "        return ' '.join([word for word in cleaned_text if word not in stopwords.words('english')])\n",
    "\n",
    "    #remove non-english words.\n",
    "    def remove_nonenglishWords(self,sentence):\n",
    "        \n",
    "        words = set(nltk.corpus.words.words())\n",
    "        return(\" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words \n",
    "                        or not w.isalpha()))\n",
    "    \n",
    "    def cleancontent(self):\n",
    "        \n",
    "        self.df['content']=self.df['content'].apply(lambda x: self.remove_nonenglishWords(x) )\n",
    "        self.df['content']=self.df['content'].apply(lambda x: self.remove_stop_punc(x) )\n",
    "    \n",
    "    def getUniqueWordCount(self):\n",
    "        self.df['no_words'] = self.df['content'].apply(lambda x: len(collections.Counter(x.split()) ) )\n",
    "    \n",
    "    def questionmarkcount(self):\n",
    "        self.df['ques_cnt'] = self.df['content'].apply(lambda x : collections.Counter(x)['?'] )\n",
    "    \n",
    "    def removedigit(self):\n",
    "        self.df['content'] = self.df['content'].apply(lambda x:  x.translate(None, string.digits))\n",
    "    \n",
    "    def removeshortwords(self):\n",
    "        length=2\n",
    "        shortwordlist = self.getallshortwords()\n",
    "        self.df['content'] = self.df['content'].apply(lambda x: ' '.join([token for token in x.split(' ') if (token not in shortwordlist)]))\n",
    "        \n",
    "    def getshortwords(self,sent,leng=2):\n",
    "        return([x for x in sent.split() if ( (len(x) <= leng) & (x != '?') )])  \n",
    "           \n",
    "    def getallshortwords(self):\n",
    "        \n",
    "        allwords = []\n",
    "        allwords.append(self.df['content'].apply(lambda x: self.getshortwords(x)))\n",
    "        return(set(sum(sum(allwords,[]),[])))\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,*)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
